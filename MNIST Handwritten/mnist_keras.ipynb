{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAMIUjlllPz2"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "Load train and test data in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8yI5AnKtqcIT",
    "outputId": "33097ffe-8d48-4736-c24d-b15906159821"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyRo7QLBlPz6"
   },
   "outputs": [],
   "source": [
    "def read_mnist(images_path: str, labels_path: str):\n",
    "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
    "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path,'rb') as imagesFile:\n",
    "        length = len(labels)\n",
    "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
    "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
    "                        .reshape(length, 784) \\\n",
    "                        .reshape(length, 28, 28, 1)\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrFPdvPslPz9"
   },
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "\n",
    "train['features'], train['labels'] = read_mnist('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
    "test['features'], test['labels'] = read_mnist('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['features'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ilx5Nw9mlP0B"
   },
   "source": [
    "### Explore the data\n",
    "\n",
    "It is always a good to do some data exploration before we start using it, find outliers, and decide if we need a preprocessing phase to uniform or augment it. And also to make sure that all the classes are covered by or more or less the same number of samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hUBaXBLalP0C",
    "outputId": "4554e692-a30a-4657-9308-f9a9d769cd69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 60000\n",
      "# of test images: 10000\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of test images:', test['features'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PT_AVb3FlP0J"
   },
   "source": [
    "#### Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HUM9-qolP0J"
   },
   "outputs": [],
   "source": [
    "def display_image(position):\n",
    "    image = train['features'][position].squeeze()\n",
    "    plt.title('Example %d. Label: %d' % (position, train['labels'][position]))\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAuHkaO9lP0c"
   },
   "source": [
    "#### Plot training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "5zp3oRg6lP0d",
    "outputId": "c6c95604-b750-4bb2-ac30-b8bd0cf61d3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Count\n",
       "0      0   5923\n",
       "1      1   6742\n",
       "2      2   5958\n",
       "3      3   6131\n",
       "4      4   5842\n",
       "5      5   5421\n",
       "6      6   5918\n",
       "7      7   6265\n",
       "8      8   5851\n",
       "9      9   5949"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_count = np.unique(train['labels'], return_counts=True)\n",
    "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
    "dataframe_train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITP1VqvUlP0m"
   },
   "source": [
    "### Split training data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yX8oIOHblP0p"
   },
   "outputs": [],
   "source": [
    "validation = {}\n",
    "train['features'], validation['features'], train['labels'], validation['labels'] = train_test_split(train['features'], train['labels'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IZhNBCFylP0s",
    "outputId": "580482ae-dbce-4fc4-aecc-c5fe31aa0cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 48000\n",
      "# of validation images: 12000\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of validation images:', validation['features'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFBt-mvYsEhM"
   },
   "source": [
    "## 2. Prepare our input features\n",
    "\n",
    "The LeNet architecture accepts a 32x32 pixel images as input, mnist data is 28x28 pixels. We simply pad the images with zeros to overcome that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1w66ueiLlP0k",
    "outputId": "f92146bb-ee68-4132-f83c-dbdb2736758a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLdfGt_GlP0x"
   },
   "source": [
    "## 3. LeNet-5 implmentation\n",
    "\n",
    "#### Input\n",
    "    32x32x1 pixels image\n",
    "\n",
    "#### Architecture\n",
    "* **Convolutional #1** outputs 28x28x6\n",
    "    * **Activation** any activation function, we will `relu`\n",
    "\n",
    "* **Pooling #1** The output shape should be 14x14x6.\n",
    "\n",
    "* **Convolutional #2** outputs 10x10x16.\n",
    "    * **Activation** any activation function, we will `relu`\n",
    "\n",
    "* **Pooling #2** outputs 5x5x16.\n",
    "    * **Flatten** Flatten the output shape of the final pooling layer\n",
    "\n",
    "* **Fully Connected #1** outputs 120\n",
    "    * **Activation** any activation function, we will `relu`\n",
    "\n",
    "* **Fully Connected #2** outputs 84\n",
    "    * **Activation** any activation function, we will `relu`\n",
    "\n",
    "* **Fully Connected (Logits) #3** outpute 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MmrzqjzAkyG"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "pup0iGQS6EOB",
    "outputId": "13f59b98-efaf-4b0d-bb4c-4f5ce224168e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdhXdD3HU3CV"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaKozfPjYIpF"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2em2DGdV0E6"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], to_categorical(train['labels'])\n",
    "X_validation, y_validation = validation['features'], to_categorical(validation['labels'])\n",
    "\n",
    "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "x61q492UX9uq",
    "outputId": "7c26c991-76da-4f8c-f22a-8c0f0f59553a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 48000\n",
      "# of validation images: 12000\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 38s 101ms/step - loss: 0.2555 - accuracy: 0.9217 - val_loss: 0.1179 - val_accuracy: 0.9749\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 37s 99ms/step - loss: 0.0763 - accuracy: 0.9761 - val_loss: 0.0799 - val_accuracy: 0.9784\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 35s 93ms/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.1146 - val_accuracy: 0.9848\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 37s 98ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.1692 - val_accuracy: 0.9815\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 33s 89ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0143 - val_accuracy: 0.9858\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 30s 79ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0271 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 37s 99ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0715 - val_accuracy: 0.9819\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 37s 98ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.0197 - val_accuracy: 0.9842\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 37s 98ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0952 - val_accuracy: 0.9843\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 37s 100ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0421 - val_accuracy: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f87a0a3e198>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of validation images:', validation['features'].shape[0])\n",
    "\n",
    "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
    "validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
    "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                    shuffle=True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pP5HvSztZ-7J",
    "outputId": "66918e13-59fd-428a-abaa-5eee4abd15ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 254us/step\n",
      "Test loss: 0.05238446573858855\n",
      "Test accuracy: 0.9860000014305115\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test['features'], to_categorical(test['labels']))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150\n",
      "   93   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253\n",
      "  218  30   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253\n",
      "  253 122   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206\n",
      "  253 140   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248\n",
      "  253  65   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(test['features'][1][:,:,0],cmap=plt.cm.gray_r)\n",
    "plt.show()\n",
    "print(test['features'][1][5:10,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "(1, 32, 32)\n",
      "(1, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "testcase = test['features'][1][:,:,0]\n",
    "print(testcase.shape)\n",
    "testcase = testcase[np.newaxis,:,:]\n",
    "print(testcase.shape)\n",
    "testcase = testcase[:,:,:,np.newaxis]\n",
    "print(testcase.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6533672e-10, 5.4091220e-09, 1.0000000e+00, 1.2546227e-12,\n",
       "        1.1491643e-10, 7.0295514e-15, 1.5817489e-10, 4.3433573e-10,\n",
       "        1.8730222e-09, 7.4556509e-15]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(testcase)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist-keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
